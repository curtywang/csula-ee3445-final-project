{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4507b8d4-cc03-437c-9fb1-68001236fc83",
   "metadata": {},
   "source": [
    "# Multiprocessing in Python\n",
    "\n",
    "What happens if we need to do a lot of computation that is mostly the same type?\n",
    "\n",
    "Basically: How can we assign different tasks to different cores or processors?\n",
    "\n",
    "## Multiprocessing systems/interfaces\n",
    "\n",
    "There are a few types of multiprocessing interfaces we can use:\n",
    "\n",
    "| Interface | When to use |\n",
    "|-----------|-------------|\n",
    "| multiprocessing | The classic built-in multiprocessing library.  || multiprocessing | The classic built-in multiprocessing library.  |\n",
    "| concurrent.futures.ProcessPoolExecutor | The modern way to launch parallel tasks. Usable for everything that takes a long time and needs to run on only one computer. Sometimes is slow, though. |\n",
    "| multiprocess | An improved version of the built-in `multiprocessing` library. A bit more manual than the pools. || multiprocess | An improved version of the built-in `multiprocessing` library. A bit more manual than the pools. |\n",
    "| mpi4py.futures.MPIPoolExecutor | The modern way to run scalable parallel tasks on computer clusters. Use for long tasks that need to run on more than one computer. |\n",
    "| mpi4py classic | A bit beyond the scope of this class. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6629d-f089-4841-a8a8-97b1a297d04a",
   "metadata": {},
   "source": [
    "### Using the `multiprocessing.Pool` interface\n",
    "\n",
    "To illustrate the use of the `multiprocessing` interface, we'll show a demonstration of the different components of the interface.\n",
    "\n",
    "Functions or software applications that can run completely independently based only on the inputs given to them are perfectly parallel (formerly known as [embarrassingly parallel](https://en.wikipedia.org/wiki/Embarrassingly_parallelhttps://en.wikipedia.org/wiki/Embarrassingly_parallel)).\n",
    "\n",
    "Thus, we recommend for this project that you choose a software application that is perfectly parallel to illustrate the effects easier.  These perfectly parallel software applications can run completely within their own memory address space, which makes it simpler for you as a software developer.\n",
    "\n",
    "We'll use a sample function below, which simply just wastes time.  Despite it being a bit useless, it's clear in how it operates, so it can illustrate the `multiprocessing` concepts a lot easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde4149-97ec-4cdc-b1dd-1e00098614ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def long_running_function(some_value: int) -> int:\n",
    "    \"\"\"\n",
    "    Performs a long-running function that wastes time for obvious throughput improvements.\n",
    "    \n",
    "    :param some_value: some integer value in seconds that we will sleep for\n",
    "    :returns: the number of seconds this function took to complete (roughly)\n",
    "    \"\"\"\n",
    "    print(f\"running long_running_function with {some_value}\")\n",
    "    time.sleep(some_value)\n",
    "    print(f\"completed long_running_function with {some_value}\")\n",
    "    return some_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac46be-2c7d-4288-80a2-9ca763d84da1",
   "metadata": {},
   "source": [
    "Now that we have this function, let's say that our software application just requires calling this function for some data items, in order to process it.  How long would it take to process this data serially using our long-running function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60118eb-8e5e-47cc-86ff-ebb31fa06a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_process = [3, 5, 10, 15, 17, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929b4c9-2b64-45a8-9f40-b83294af8398",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "return_items = []\n",
    "for item in items_to_process:\n",
    "    return_val = long_running_function(item)\n",
    "    return_items.append(return_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b6d9b-0aae-4b0b-98f7-739e84a9b0fb",
   "metadata": {},
   "source": [
    "This took way longer than it needed to!  You may be wondering about the `%%time` command.  That simply records both the Wall (clock) time and the CPU time and reports it to you.  We can see that our function was not computationally difficult since the CPU time was extremely low, so can definitely benefit from parallel computing even if we do not have more than two CPU cores.  The operating system will switch between the processes for us in the case that we do not have enough cores.\n",
    "\n",
    "As you may remember, especially since data transfer (input/output or I/O) between disks or network devices trigger interrupts, the CPU and operating system will not hang on a function waiting for transfer, since the system can just do something else until the transfer interrupt comes back.\n",
    "\n",
    "It is similar for the `sleep()` function, which triggers a software interrupt in the system.  Note that if you do something computationally expensive (difficult) requiring a lot of CPU time, then you will need many CPU cores (as you will see in Component 3 of this project).\n",
    "\n",
    "Now, we'll present some code that runs the processing in parallel instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5aeaf-0835-42e3-89f7-8f91b4e915ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "with mp.Pool(processes=4) as pool:\n",
    "    p_return_items = pool.map(long_running_function, items_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612cfed-94f9-4ca1-83ef-ca264be98a27",
   "metadata": {},
   "source": [
    "What are the Wall time and CPU times now?  Was the Wall time much shorter?  How do they compare to the times from before?\n",
    "\n",
    "You might have noticed a couple of things:\n",
    "\n",
    "- the `print()` statements are all jumbled -- this is because the operating system receives many at a time, it just goes along with \"first characters first served\"\n",
    "- the `with` keyword in Python, which uses a context manager so that you don't have to call `close()` functions on any handles (think of it as an easier way to allocate/deallocate resources simply by scope)\n",
    "- the `Pool` object, which creates a pool of *worker* processes, which are simply copies (usually via `fork()` but sometimes via `spawn()` if needed) of the Python interpreter with your code loaded\n",
    "- the `processes=4` parameter passed to the `Pool()` constructor function, which indicates the number of workers to use\n",
    "- the call to `pool.map()`, which allows us to use the higher-order `map()` function in parallel, which accepts a function as its first input parameter and an iterable (such as a list) as its second input parameter.  As you may have assumed, each item in the iterable becomes the input parameter passed to the function that runs on each worker.\n",
    "\n",
    "What happens if we double the number of worker processes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe8cd7-ccb8-4ad9-89c8-df61c79c637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with mp.Pool(processes=8) as pool:\n",
    "    p_return_items = pool.map(long_running_function, items_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3fe415-4cfd-44ce-99f2-db136756bdf8",
   "metadata": {},
   "source": [
    "What was the Wall time now?  Can we improve the Wall time any further?  Why or why not?\n",
    "\n",
    "What about the CPU time?  Was it shorter or longer?\n",
    "\n",
    "If we look, we see that the user CPU time has only gone up a little bit, but we see a lot more on the system CPU time.  This means that the operating system is doing more work, which is understandable as we might not have exclusive access to 8 CPU cores.\n",
    "\n",
    "The Wall time, on the other hand, is now only slightly longer than the longest function run (which is supposed to run for 20 seconds).  We can see the significant improvement in throughput now!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a273959-6840-49dd-871e-c69bdb644bb5",
   "metadata": {},
   "source": [
    "#### Using `multiprocessing.starmap`\n",
    "\n",
    "So [`Pool.map()`](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.map) works pretty well, if we only take one input parameter into our function.  If our function is realistic, though, then we will have a multitude of input parameters.\n",
    "\n",
    "In this case, we can use [`Pool.starmap()`](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.starmap) instead, by giving each function call a tuple (fixed list) of parameter inputs that `Pool.starmap()` will unpack into input parameters for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0533ba1b-f6f4-47ab-abad-58717ffaa414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_running_function_enhanced(some_value: int, some_other_value: str) -> int:\n",
    "    \"\"\"\n",
    "    Performs a long-running function that wastes time for obvious throughput improvements.\n",
    "    \n",
    "    :param some_value: some integer value in seconds that we will sleep for\n",
    "    :param some_other_value: some string value that we will just use to print\n",
    "    :returns: the number of seconds this function took to complete (roughly)\n",
    "    \"\"\"\n",
    "    print(f\"running long_running_function with {some_value}, {some_other_value}\")\n",
    "    time.sleep(some_value)\n",
    "    print(f\"completed long_running_function with {some_value}, {some_other_value}\")\n",
    "    return some_value\n",
    "\n",
    "\n",
    "enh_items_to_process = [(3, 'a'), (5, 'b'), (10, 'c'),\n",
    "                        (15, 'd'), (17, 'e'), (20, 'f')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a5baf-3a0f-463d-8f2a-1ec614337c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with mp.Pool(processes=8) as pool:\n",
    "    pe_return_items = pool.starmap(\n",
    "        long_running_function_enhanced,\n",
    "        enh_items_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121fca3-fd0b-4af8-a5b8-32c17f068512",
   "metadata": {},
   "source": [
    "### Basic Linear Algebra Problems in Multiprocessing\n",
    "\n",
    "This is a note if you are planning on augmenting code that uses matrix algebra libraries (very likely if you are planning on augmenting the suggested examples).\n",
    "\n",
    "Turns out that the Math Kernel Library or any other basic linear algebra system (BLAS) sometimes will try to be sneaky and do multiprocessing/multithreading on its own.  However, this conflicts with your own code, so make sure to do this before importing numpy or any other packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b853123-e573-40bf-ba21-860c6ceb55ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "# now you can import numpy and other packages\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f22b3f-fabe-460e-82fb-78938a30edc0",
   "metadata": {},
   "source": [
    "### Converting serial code to parallel code\n",
    "\n",
    "As discussed earlier, parallelizing serial code is easiest when the problem is perfectly parallel.  This means that we can split our problem in such a way that the workers can work independently on some portion of our problem, then just assemble at the end.\n",
    "\n",
    "In this case, we distribute our data such that each worker computes a chunk of it instead.  This technique is called [map-reduce](https://courses.cs.washington.edu/courses/cse490h/07wi/readings/IntroductionToParallelProgrammingAndMapReduce.pdf), because we map a function and chunk of data to a worker, collect all of the results, and then aggregate them using a reduction technique (such as the sum, mean, min, max).\n",
    "\n",
    "![map_reduce_image](assets/map_reduce.webp)\n",
    "_Figure: The diagram illustrating this map and reduction parallel code architecture.  From: https://www.mdpi.com/1999-4893/8/3/407_\n",
    "\n",
    "Let's see how this works when it comes to performing something such as a sum of a 20000-item array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e247e3-d7b3-4220-8537-62fce3d34714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sum(in_array: np.ndarray) -> float:\n",
    "    output = 0.0\n",
    "    for item in in_array:\n",
    "        output += item\n",
    "    return output\n",
    "\n",
    "\n",
    "def p_compute_sum(input_array: np.ndarray, pool: mp.Pool,\n",
    "                  num_workers: int = 4) -> float:\n",
    "    \"\"\"\n",
    "    Distribute an 'equal' chunk of the input_array array to\n",
    "      each worker, map the sum compute function to each worker \n",
    "      to compute their individual sums, then sum (reduce) the smaller\n",
    "      number of partial sums.\n",
    "    \n",
    "    :param input_array: some large 1D array of numbers\n",
    "    :param num_workers: number of workers to use in the pool\n",
    "    :returns: the sum of the floats in input_array\n",
    "    \"\"\"\n",
    "    offset = len(input_array) % num_workers\n",
    "    amount_to_pad = num_workers - (offset) if offset > 0 else 0\n",
    "    full_array = np.pad(\n",
    "        array=input_array, pad_width=(0, amount_to_pad), mode='constant')\n",
    "    orig_size = len(full_array)\n",
    "    reshaped_array = full_array.reshape(\n",
    "        (orig_size // num_workers, num_workers))\n",
    "    results = pool.map(compute_sum, reshaped_array)  # map\n",
    "    sum_result = np.sum(results)  # reduce\n",
    "    return sum_result\n",
    "\n",
    "\n",
    "def check_sum() -> None:\n",
    "    num_workers = 16\n",
    "    with mp.Pool(processes=num_workers) as pool:  # start the pool first\n",
    "        random_array = np.random.default_rng().uniform(\n",
    "            low=-24.5, high=72.4, size=2000000)\n",
    "        serial_sum = compute_sum(random_array)\n",
    "        parallel_sum = p_compute_sum(random_array, pool)\n",
    "        print(f\"serial result: {serial_sum}\")\n",
    "        print(f\"parallel result: {parallel_sum}\")\n",
    "        # Note: use np.isclose() instead of ==\n",
    "        #       since floats have some precision\n",
    "        print(np.isclose(serial_sum, parallel_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1328357a-89d4-4473-9f1f-fa08bcb716ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ae76f-1740-43cd-8d34-7319fb404270",
   "metadata": {},
   "source": [
    "If you perform the timings using the tools in the next notebook, you might notice that the parallel sum computation is slower than the serial.  This is simply because a sum is faster to compute than to send data to the worker processes. Thus, often parallelization is a point of discussion and not always the best answer.\n",
    "\n",
    "You're now ready to use the `multiprocessing.Pool` interface!\n",
    "\n",
    "If you'd like more information, here are some additional resources:\n",
    "\n",
    "- https://people.duke.edu/~ccc14/sta-663-2016/19B_Threads_Processses_Concurrency.html#Using-multiprocessing\n",
    "- https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool\n",
    "- https://docs.python.org/3/library/multiprocessing.html#examples  (scroll down to \"Using Pool\")\n",
    "- https://courses.cs.washington.edu/courses/cse490h/07wi/readings/IntroductionToParallelProgrammingAndMapReduce.pdf\n",
    "- https://cs.boisestate.edu/~amit/teaching/530/handouts/ep.pdf (general information on parallel processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029d96a-4a74-42bb-a143-e867473efb25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
