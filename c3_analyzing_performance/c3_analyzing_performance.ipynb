{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53d26b9-7505-433b-9361-e497c1ddccac",
   "metadata": {},
   "source": [
    "# Analyzing Performance\n",
    "\n",
    "## Using Linux built-in performance measurement tools\n",
    "\n",
    "One of the most prolific tools (as you may have read in the textbook) is the `time` ([man page](https://man7.org/linux/man-pages/man1/time.1.html)) tool built into Linux and BSD (amongst other operating systems), usually located at `/usr/bin/time`.  To run `/usr/bin/time`, simply just add it on the same line where you call `python` or your compiled program at the beginning of the line in your `%%qsub` cells.  \n",
    "\n",
    "Note that it will print, by default: the CPU usage by the program code (user), the CPU usage by the system (system), the Wall time (elapsed), the percentage of CPU used, and different information about the RAM usage.\n",
    "\n",
    "You can customize it yourself by feeding the `--format=\"...\"` parameters, by replacing the ellipsis with a printf-style format string.\n",
    "\n",
    "For instance, if we want to time the program `sleep 5`, with the format string `\"real %e system %S cpu %P avg_ram_kb %K\"`, our line would look like:\n",
    "\n",
    "`/usr/bin/time --format=\"real %e system %S cpu %P avg_ram_kb %K\" sleep 5`\n",
    "\n",
    "**NOTE**: The output from this tool will appear in the error buffer instead (`STDIN.eNNNNNN`), so make sure you look for through both the standard output and the standard error files.  Make sure to look through the `STDIN.oNNNNN` file too, so that you have the job number and can know which run was with which parameters.\n",
    "\n",
    "Try using this tool on your code in the following cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc0905-512b-4f42-b01e-4b7d06f617a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670c142-97e2-4336-b9b6-12532014c02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "625ad6c1-5c94-41d4-9cc8-1772a5a332b7",
   "metadata": {},
   "source": [
    "## Collecting run data\n",
    "\n",
    "To make sure that we have adequate data, make sure to submit at least 10 different variations of your code, such as the following example variations (based on the Monte Carlo example):\n",
    "\n",
    "1. Run with draw number size 10000000 and 2 workers\n",
    "1. Run with draw number size 10000000 and 4 workers\n",
    "1. Run with draw number size 10000000 and 6 workers\n",
    "1. Run with draw number size 10000000 and 8 workers\n",
    "1. Run with draw number size 10000000 and 10 workers\n",
    "1. Run with draw number size 10000000 and 12 workers\n",
    "1. Run with draw number size 10000000 and 14 workers\n",
    "1. Run with draw number size 10000000 and 16 workers\n",
    "1. Run with draw number size 100000000 and 8 workers\n",
    "1. Run with draw number size 100000000 and 16 workers\n",
    "1. Run with draw number size 1000000000 and 8 workers\n",
    "1. Run with draw number size 1000000000 and 16 workers\n",
    "1. Run with draw number size 10000000000 and 8 workers\n",
    "1. Run with draw number size 10000000000 and 16 workers\n",
    "\n",
    "Now, go ahead and use the two cells below to run your job for different variations (you can either programmatically run the variations or just manually run each variation here and just note the data down)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1270352-f5ba-48dd-816f-2d1fce8a5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cfxmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf334b8-79a1-4f79-8060-b1dbbee340c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97fea7a7-3a31-40c4-8350-c64820b4a9e3",
   "metadata": {},
   "source": [
    "We can also submit to different types of machines.  The Intel(R) Core(tm) processors differ in specifications from the Intel(R) Xeon(tm) processors.  To switch between the Intel Core nodes and the Intel Xeon nodes, simply just call `qsub` with different node properties as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963f7ee-d184-4cfa-9b3d-45ac3dadc4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%qsub -l nodes=1:core:ppn=2\n",
    "cd $PBS_O_WORKDIR\n",
    "python ParallelCode.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97046ca7-2500-4d75-a127-c432316f8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%qsub -l nodes=1:xeon:ppn=2\n",
    "cd $PBS_O_WORKDIR\n",
    "python ParallelCode.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d583d4-0a3d-421a-9d39-fc8fdbd91d08",
   "metadata": {},
   "source": [
    "## Generating plots\n",
    "\n",
    "We would like to generate plots using the data we collected above.  Optimally, we'd generate data files that we could just simply import and plot, but for this time, it's okay to just create lists of data manually as this isn't really a class on data analysis.\n",
    "\n",
    "A nice video explaining plotting in Jupyter notebooks is available at: https://www.youtube.com/watch?v=Hr4yh1_4GlQ\n",
    "\n",
    "Practice by plotting the number of workers (or another variable, such as data draw size) against a response (such as wall time, cpu time, memory usage, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e641b4-3460-456b-bda3-bc6b93215795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b8bac-d50e-4024-b002-60cf5c86d43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86774e4-a9e7-4a17-b5e9-631d4d72f97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d17fb8c5-00a3-4812-8309-8b8a14b9c8c6",
   "metadata": {},
   "source": [
    "## Presenting data/plots inline with Markdown text\n",
    "\n",
    "Now that you have your data and know how to plot your data, create Markdown and code cells below to answer the following questions in report format (incorporating the code cells to generate plots):\n",
    "\n",
    "1. What software application did you choose to attempt to parallelize or augment?\n",
    "2. How did you parallelize or augment your chosen software application?\n",
    "3. How did the throughput or latency of your software application change as you increased the number of resources (workers, CPUs, etc.)?\n",
    "4. Were there any differences between the Linux system performance measurement tools and your language-based measurement tools?  What may be the cause of that?\n",
    "5. What would you change if you were to attempt this project again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05b831-1103-40e5-802a-558e9f29a7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae565b1-b794-403f-92df-0353683a0672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
